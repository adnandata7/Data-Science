{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190af039-4271-4c3b-b83f-9dc9c8d78bf5",
   "metadata": {},
   "source": [
    "#### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd16a7-3eaa-457d-adcf-7b1e1886ea37",
   "metadata": {},
   "source": [
    "Web scraping is the automated process of extracting data from websites. It involves using software to simulate human web browsing to collect information that is publicly available on websites. Web scraping is used for various reasons, including:\n",
    "\n",
    "Data Collection and Analysis: Companies use web scraping to gather large amounts of data from multiple sources for analysis, such as market research, competitor analysis, and trend monitoring.\n",
    "\n",
    "Content Aggregation: Websites aggregate content from various sources using web scraping to create comprehensive databases or directories, such as news aggregation sites or job boards.\n",
    "\n",
    "Research and Monitoring: Academic researchers and professionals use web scraping to collect data for studies, monitor online sentiment, or track changes in websites over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c826d3-3042-4b70-ba28-92b341701023",
   "metadata": {},
   "source": [
    "#### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12534cd-0bfb-437a-b681-4597a1854a85",
   "metadata": {},
   "source": [
    "Web scraping can be performed using various methods and tools. Some common methods include:\n",
    "\n",
    "Using Web Scraping Libraries: Libraries like BeautifulSoup (for parsing HTML and XML documents), Scrapy (a full-fledged web scraping framework), and Selenium (for browser automation) are popular choices.\n",
    "\n",
    "HTTP Requests: Directly sending HTTP requests to web servers and parsing the HTML or JSON responses.\n",
    "\n",
    "APIs: Some websites provide APIs (Application Programming Interfaces) that allow access to their data in a structured way, which can be a more reliable and ethical way to gather data compared to scraping HTML directly.\n",
    "\n",
    "Headless Browsers: Tools like Puppeteer (for Node.js) or Selenium WebDriver (for Python and other languages) can automate browsers to interact with web pages and extract data.\n",
    "\n",
    "Manual Scraping: Sometimes, manual copying and pasting of data from web pages might be sufficient for small-scale projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3db707-1d5a-445a-841a-40dd37003e74",
   "metadata": {},
   "source": [
    "#### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a42df-ace4-423f-a9ef-2f79028e7c5e",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It creates a parse tree from page source that can be used to extract data easily. It is used in web scraping projects to navigate and search the parsed HTML or XML, extract data, and manipulate it as needed. Beautiful Soup handles malformed markup well and provides a simple interface for extracting information from web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ec863-d02d-4ce8-a259-74122734addb",
   "metadata": {},
   "source": [
    "#### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971a863-8f45-4bc8-b9f5-99d81ef7f3e4",
   "metadata": {},
   "source": [
    "Web scraping can be performed using various methods and tools. Some common methods include:\n",
    "\n",
    "Using Web Scraping Libraries: Libraries like BeautifulSoup (for parsing HTML and XML documents), Scrapy (a full-fledged web scraping framework), and Selenium (for browser automation) are popular choices.\n",
    "\n",
    "HTTP Requests: Directly sending HTTP requests to web servers and parsing the HTML or JSON responses.\n",
    "\n",
    "APIs: Some websites provide APIs (Application Programming Interfaces) that allow access to their data in a structured way, which can be a more reliable and ethical way to gather data compared to scraping HTML directly.\n",
    "\n",
    "Headless Browsers: Tools like Puppeteer (for Node.js) or Selenium WebDriver (for Python and other languages) can automate browsers to interact with web pages and extract data.\n",
    "\n",
    "Manual Scraping: Sometimes, manual copying and pasting of data from web pages might be sufficient for small-scale projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3570c-a072-4aa9-88ac-e5770c7d0f60",
   "metadata": {},
   "source": [
    "#### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdbd9a-d579-42a0-ac43-6340e05e0f4f",
   "metadata": {},
   "source": [
    "AWS Elastic Beanstalk:\n",
    "\n",
    "Use: AWS Elastic Beanstalk is a Platform-as-a-Service (PaaS) offering that simplifies the deployment and management of web applications and services. It supports various programming languages and frameworks, making it ideal for deploying Flask or other web applications used in web scraping projects.\n",
    "\n",
    "AWS CodePipeline:\n",
    "\n",
    "Use: AWS CodePipeline is a fully managed Continuous Integration and Continuous Delivery (CI/CD) service. It automates the build, test, and deployment of your application code whenever there are changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fbe8b-d4b8-4a73-8323-deb5175403df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
